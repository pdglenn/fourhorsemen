{% extends 'base.html' %}
{% block content %}
{% load static %}
<!-- Page Content -->

<script> var data = "{% static 'data/false_pos_neg.json' %}" </script>
<script src="{% static 'js/bar_chart_percent.js' %}"></script>
<script src="{% static 'js/free_speech.js' %}"></script>

<div id="page-content-wrapper">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2">
        <p class="lead">When moderating content online, which of the following scenarios is more important to prevent?</p>
        <div class="col-lg-6">
          <img src="{% static 'img/generic-un-free_speech.png' %}" class="img-responsive center-block" alt="image of a potentially harassing social media post">
          <p class="message-caption">Non-harassing content being flagged as harassing and potentially subjected to remediation</p>
          <button class="btn btn-primary next_button last" type="button" style="margin:auto;display:block" onclick="freeSpeech('False Positive')">Prevent False Positives</button>
        </div>
        <div class="col-lg-6">
          <img src="{% static 'img/no_flag-un-free_speech.png' %}" class="img-responsive center-block" alt="image of a potentially harassing social media post">
          <p class="message-caption">Harassing content not being flagged as harassing and not subjected to remediation</p>
          <button class="btn btn-primary next_button last" type="button" style="margin:auto;display:block" onclick="freeSpeech('False Negative')">Prevent False Negatives</button>
        </div>
      </div>
    </div>
    <div class="row bottom_content">
      <div class="col-lg-8 col-lg-offset-2">
        <section id="">
          <a name="bottom_content"></a>
          <h3>Speech Considerations</h3>
          <p>We asked our participants to answer this question while imagining they were building a computational tool to automatically detect harassing content online. We were surprised that three times as many people wanted to prevent false negatives, that is, having genuinely harassing content get through the filter and reach the public or its target. We found this surprising, given the open nature of the internet and frequent commentary about protected speech on the internet.</p>
        </section>

        <section id="chart">
          <div id="chart" align="center">
          </div>
        </section>

        <section id="">
          <p>Presently, the bulk of the work of content moderation is done by human moderators, but platforms are more and more turning to automated, algorithmic mechanisms to support or take over the work of addressing the problem of harassment at scale. This shift to algorithmic moderation raises interesting and important questions about the role technology should take, and the extent to which communities should delegate the work of enforcing their morals to machines. Do we envision a future where the machines themselves decide what is acceptable in public discourse?
          </p>
          <p>Under Section 230 of the Communications Decency Act, platforms in the United States can make these moderation and delegation choices behind the scenes, without any requirements to publicize any methodology or details of the process—regardless of whether the speech would be Constitutionally protected. This lack of procedural transparency raises questions about the role of free speech—both of and on platforms. As private corporations, platforms can legally make these moderation choices, yet complex decisions with potentially broad ramifications are made without public input or reflection. For instance, content moderators routinely make decisions on whether violent imagery, which might violate their terms of use, should have an exception if it’s newsworthy. But what constitutes “newsworthy,” and does it align with or contradict public policy?</p>
          <p>The current method of flagging and deleting erases any evidence that there was, or should have been, a conflict about whether or not to remove content. Our finding that survey participants were more willing to put speech at risk becomes more worrisome as platforms become more dominant forms of public discourse. The disparity between what’s allowed in the physical public and what’s allowed in the virtual “public” can lead to intolerance of ideas at the margins within these spaces, which has greater and greater effects as platforms become widespread.</p>
        </section> 

        <section id="">
          <p>In this vein, we love this comic and agree with its sentiment, but there’s also a bit more at stake with this particular issue:</p>
          <img src="https://imgs.xkcd.com/comics/free_speech.png">
          <p class="message-caption">Source: <a href="https://xkcd.com/1357/" target="_blank">XKCD</a></p>
        </section>                       

        <section class="last">
          <a href="{{ next }}"><button class="btn btn-primary" type="button">Next Page</button></a>
        </section>
      </div>
    </div>
  </div>
</div>
{% endblock %}
