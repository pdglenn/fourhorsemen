{% extends 'base.html' %}
{% block content %}
{% load static %}

<script> var fair = "{% static 'data/fair.json' %}" </script>
<script> var accurate = "{% static 'data/accurate.json' %}" </script>
<script> var trust = "{% static 'data/trust.json' %}" </script>
<script src="{% static 'js/bar_chart.js' %}"></script>
<script src="{% static 'js/who_moderates.js' %}"></script>
  <!-- Page Content -->
<div id="page-content-wrapper">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2">
        <p class="lead">Which type of moderator do you prefer?</p>
      </div>
      <div class="col-lg-8 col-lg-offset-2">
        <form action="/content_assessment/" method="POST" role="form">
        {% csrf_token %}
        <div class="form-group">
          <br><br>
          {{ form.errors }}
          {% for f in form %}
          <b class="question">{{ f.label }}</b>
          <table id="{{ forloop.counter }}">
            <tr>
              {% for value, text in f.field.choices %}
                <th width="20%" class="matrix-centered options">{{ text }}</th>
              {% endfor %}
            </tr>
            <tr>
              {% for value, text in f.field.choices %}
                <td class="matrix-centered scale">
                  <input type="radio" name="{{ f.html_name }}" value="{{ value }}">
                </td>
              {% endfor %}
            </tr>
          </table>
          <br><br>
          {% endfor %}
        </div>
        <button type="button" id="next_button" class="btn btn-primary last" onclick="whoModerates(0)">Click to See Results</button>
        </form>
      </div>
    </div>

    <div class="row bottom_content">
      <div class="col-lg-8 col-lg-offset-2">
        <section id="">
          <a name="bottom_content"></a>
          <h3>Who Moderates?</h3>
          <p>We found that most participants showed a preference for human moderation and judgment in determining whether content was harassing. People just don’t trust algorithms enough to do this type of work yet.</p>
          <p>However, this reliance on human moderation means we are asking real people to sift through disturbing content day in and day out. Being the recipient of this type of message is traumatic. It can also be traumatic to have to comb through thousands of similar messages (many with images!) every hour. For instance, here are the selection of images we asked participants to rate, all of which were easily found on social media:</p>
          <img src="{% static 'img/terrible-things.gif' %}" class="img-responsive center-block" alt="image of a potentially harassing social media post">
          <br>
          <p>Human moderators might do a better job, but is it worth the risks to their mental health? And they don’t scale as well as computers. If you want to learn more, you might want to check out some recent media coverage about content moderators:</p>
          <ul style="color:rgba(255, 255, 255, 0.7)">
            <li>WIRED: <a href="https://www.wired.com/2014/10/content-moderation/" target="_blank">“The Laborers Who Keep Dick Pics and Beheadings Out of Your Facebook Feed”</a></li>
            <li>The Atlantic: <a href="https://www.theatlantic.com/technology/archive/2017/03/commercial-content-moderation/518796/" target="_blank">“Social Media’s Silent Filter”</a></li>
            <li>Field of Vision: <a href="https://vimeo.com/213152344" target="_blank">“The Moderators”</a> (documentary)</li>
            <li>The Verge: <a href="https://www.theverge.com/2016/4/13/11387934/internet-moderator-history-youtube-facebook-reddit-censorship-free-speech" target="_blank">“THE SECRET RULES OF THE INTERNET: The murky history of moderation, and how it’s shaping the future of free speech”</a></li>
          </ul>
          <p>But the fact remains that most of us don’t yet trust that algorithms and computers will make these kinds of decisions accurately or fairly. However, other researchers have found that increasing transparency in the way that an algorithm works and what factors it takes into account can increase the trust people have in that system.</p>
        </section>

        <section id="chart">
          <script src="https://d3js.org/d3.v4.min.js"></script>
          <div id="chart1" align="center">
          </div>
          <div id="chart2" align="center">
          </div>
          <div id="chart3" align="center">
          </div>
        </section>

        <section class="last">
          <a href="{{ next }}"><button class="btn btn-primary" type="button">Next Page</button></a>
        </section>
      </div>
    </div>
  </div>
</div>
{% endblock %}
