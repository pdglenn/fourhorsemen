{% extends 'base.html' %}
{% block content %}
{% load static %}

<script> var data = "{% static 'data/algorithmic_features.json' %}" </script>
<script src="{% static 'js/horizontal_bar_chart.js' %}"></script>
<script src="{% static 'js/algorithmic_factors.js' %}"></script>

  <!-- Page Content -->
<div id="page-content-wrapper">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2">
        <p class="lead">Imagine you are creating an algorithm to detect harassing content. Which factor about a piece of content do you think it's most important that your algorithm consider in making its moderation decision?</p>
      </div>
      <div class="col-lg-8 col-lg-offset-2">
        <form action="/content_assessment/" method="POST" role="form">
          {% csrf_token %}
          <div class="form-group">
            <br><br>
           <!--  {{ form.errors }}
            {% for f in form %}
              <b class="question">{{ f.label }}</b>
              <table>
                <tr>
                  {% for value, text in f.field.choices %}
                    <th width="20%" class="matrix-centered options">{{ text }}</th>
                  {% endfor %}
                </tr>
                <tr>
                  {% for value, text in f.field.choices %}
                    <td class="matrix-centered scale">
                      <input type="radio" name="{{ f.html_name }}" value="{{ value }}">
                    </td>
                  {% endfor %}
                </tr>
              </table>
              <br><br>
            {% endfor %} -->
            {{ form }}
          </div>
          <button type="button" id="next_button" class="btn btn-primary last" onclick="algorithmicFactors(0)">Click to See Results</button>
        </form>
      </div>  
    </div>      

    <div class="row bottom_content">           
      <div class="col-lg-8 col-lg-offset-2">
        <a name="bottom_content"></a>
        <section id="">
          <h3>Algorithmic Factors</h3>
          <p>We found it interesting that a large number of respondents replied with image recognition. This might indicate that they've come across offensive or harassing images quite often. Have you?</p>
        </section>

        <section id="chart">
          <script src="https://d3js.org/d3.v4.min.js"></script>
          <div id="chart" align="center">
          </div>
        </section>

        <section id="">
          <p>As previously discussed, presently the bulk of the work of content moderation is done by human moderators, but platforms are more and more turning to automated, algorithmic mechanisms to support or take over the work of addressing the problem of harassment at scale. For example, Jigsaw recently released <a href="http://www.perspectiveapi.com/" target="_blank">Perspective</a>, an algorithm that attempts to counter abuse by assigning a piece of text a “toxicity” score, which could conceivably be used by a platform to remove messages over a certain threshold. This algorithm focuses entirely on the text content of the message itself. The first release of the Jigsaw API gives a toxicity score of 78% to “I hate bananas,” while it assigns a toxicity score of only 37% to “We must secure our existence and a future for white children” which is considered to be the most popular white supremacist slogan in the world. This highlights challenges with this approach.</p>
        </section>

        <section class="last">
          <a href="{{ next }}"><button class="btn btn-primary" type="button">Next Page</button></a>
        </section>
      </div>
    </div>
  </div>
</div>
{% endblock %}
